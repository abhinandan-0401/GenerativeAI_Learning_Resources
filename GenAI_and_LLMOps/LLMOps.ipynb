{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87ec7c11-887d-4c52-b4c3-fd0e2a253ec5",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "### Data Exploration for Tuning a Foundation Model\n",
    "\n",
    "**Project environment setup:**\r\n",
    "\r\n",
    "- Load credentials and relevant Python Libraries\r\n",
    "- If you were running this notebook locally, you would first install Vertex AI. In this classroom, this is already installed.\r\n",
    "\r\n",
    "```\r\n",
    "!pip install google-cloud-aiplatform\r\n",
    "```\r\n",
    "- You can download the `requirements.txt` for this course from the workspace of this lab. `File --> Open...`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a7d42a8-4b9d-4bec-b19c-dca5bc858624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install utils\n",
    "# !pip install google-cloud-aiplatform\n",
    "# !pip install google-auth\n",
    "# !pip install google-cloud-bigquery\n",
    "# !pip install google-cloud-storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82b64d41-cca6-4f97-ac47-f96664211d05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/abhmukherjee/Documents/Portfolio/GenerativeAI_Learning_Resources')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "path = Path(\"\\\\\".join(os.path.join(os.getcwd()).split('\\\\')[:-1]))\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "133acf9c-3f4a-41d3-ad8d-d22db7a1c1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import authenticate\n",
    "credentials, PROJECT_ID = authenticate.gcp_authenticate() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41de7b2a-e4e4-4a35-abe9-1a9977eca652",
   "metadata": {},
   "outputs": [],
   "source": [
    "REGION = \"us-central1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e788b16e-e710-4a5f-92a4-cc68c1ecb9f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\anaconda3\\envs\\dl_n_gen_ai\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import vertexai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb26e2cb-fa40-4cd0-ab77-65e331d3324d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vertexai.init(\n",
    "    project = PROJECT_ID,\n",
    "    location = REGION,\n",
    "    credentials = credentials,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3a110d0-4bea-4573-80b9-77a64f4c2c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dba67f85-89c4-47bf-8c38-3cf1d0d29416",
   "metadata": {},
   "outputs": [],
   "source": [
    "bq_client = bigquery.Client(\n",
    "    project=PROJECT_ID,\n",
    "    credentials = credentials,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767e14b1-d92b-4eec-9d21-ba2667ad530b",
   "metadata": {},
   "source": [
    "## Stack Overflow Public Dataset\n",
    "\n",
    "- We will use [Stack Overflow Data](https://cloud.google.com/blog/topics/public-datasets/google-bigquery-public-datasets-now-include-stack-overflow-q-a) on BigQuery Public Datasets.\n",
    "- The datasets include questions, answers and metadata related to Stack Overflow questions. Within this dataset, there are tables with data.\n",
    "- Create a SQL query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "600dca70-f78e-405a-8d1e-b85ea117a836",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_TABLES = \"\"\"\n",
    "SELECT\n",
    "  table_name\n",
    "FROM\n",
    "  `bigquery-public-data.stackoverflow.INFORMATION_SCHEMA.TABLES`\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c160110-ecbe-45c1-b659-cf87951bd37c",
   "metadata": {},
   "source": [
    "- The query is asking to retrieve `table_name` of all the `TABLES`\n",
    "- Use the client to send our SQL and retrieve the data (tables names)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87b31be0-96cb-4bac-8c24-91fceec6a4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_job = bq_client.query(QUERY_TABLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e588f84a-1dde-491c-84c3-869ccb383766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "posts_answers\n",
      "users\n",
      "posts_orphaned_tag_wiki\n",
      "posts_tag_wiki\n",
      "stackoverflow_posts\n",
      "posts_questions\n",
      "comments\n",
      "posts_tag_wiki_excerpt\n",
      "posts_wiki_placeholder\n",
      "posts_privilege_wiki\n",
      "post_history\n",
      "badges\n",
      "post_links\n",
      "tags\n",
      "votes\n",
      "posts_moderator_nomination\n"
     ]
    }
   ],
   "source": [
    "for row in query_job:\n",
    "    for value in row.values():\n",
    "        print(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ed05a8-67ce-474a-b701-36395fc18c8e",
   "metadata": {},
   "source": [
    "## Data Retrieval\n",
    "\n",
    "- We'll fetch some data from the data warehouse and store it in Pandas dataframe for visualization.\r\n",
    "- Select all columns from  `posts_questions` and put the `LIMIT` as 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9a95d36-6bc8-4a3b-9eb8-1906995992f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "INSPECT_QUERY = \"\"\"\n",
    "SELECT\n",
    "    *\n",
    "FROM\n",
    "    `bigquery-public-data.stackoverflow.posts_questions`\n",
    "LIMIT 3\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0cea3b91-fe81-4b27-8e74-a0f9314f8ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b3d426ff-90ab-448e-a908-264643fc7d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_job = bq_client.query(INSPECT_QUERY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bb27e2-e60c-4c91-bca1-5eeedd86c18a",
   "metadata": {},
   "source": [
    "- Take the results of the query `-->` create an arrow table (which is part of [Apache Framework](https://arrow.apache.org/docs/index.html)) `-->` which goes into a Pandas dataframe.\r\n",
    "- This allows for data to be in a format which is easier to read and explore with Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89b10cd9-6eb2-4ac8-b150-6b181f3bb379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>accepted_answer_id</th>\n",
       "      <th>answer_count</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>community_owned_date</th>\n",
       "      <th>creation_date</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>last_activity_date</th>\n",
       "      <th>last_edit_date</th>\n",
       "      <th>last_editor_display_name</th>\n",
       "      <th>last_editor_user_id</th>\n",
       "      <th>owner_display_name</th>\n",
       "      <th>owner_user_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>post_type_id</th>\n",
       "      <th>score</th>\n",
       "      <th>tags</th>\n",
       "      <th>view_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73210679</td>\n",
       "      <td>az acr login raises DOCKER_COMMAND_ERROR with ...</td>\n",
       "      <td>&lt;p&gt;Windows 11 with wsl2 ubuntu-22.04.&lt;/p&gt;\\n&lt;p&gt;...</td>\n",
       "      <td>73247188.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2022-08-02 16:16:31.810000+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-08-05 09:00:14.693000+00:00</td>\n",
       "      <td>2022-08-02 16:32:13.700000+00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>11226740</td>\n",
       "      <td>None</td>\n",
       "      <td>11226740</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>azure-container-registry|docker-daemon</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>73284406</td>\n",
       "      <td>Run Azure log query from the command line with...</td>\n",
       "      <td>&lt;p&gt;I am trying to get the Azure log query data...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2022-08-08 21:53:16.703000+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-08-10 04:49:20.527000+00:00</td>\n",
       "      <td>2022-08-09 08:12:13.920000+00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>2395282</td>\n",
       "      <td>None</td>\n",
       "      <td>19123691</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>azure|azure-devops|azure-application-insights|...</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>73250763</td>\n",
       "      <td>Error CS0246: The type or namespace name 'Stre...</td>\n",
       "      <td>&lt;p&gt;I have these errors when trying to write th...</td>\n",
       "      <td>73251390.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2022-08-05 13:43:25.850000+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-08-05 16:40:00.610000+00:00</td>\n",
       "      <td>2022-08-05 16:40:00.610000+00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>17654458</td>\n",
       "      <td>None</td>\n",
       "      <td>17654458</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>c#|unity3d</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                              title  \\\n",
       "0  73210679  az acr login raises DOCKER_COMMAND_ERROR with ...   \n",
       "1  73284406  Run Azure log query from the command line with...   \n",
       "2  73250763  Error CS0246: The type or namespace name 'Stre...   \n",
       "\n",
       "                                                body  accepted_answer_id  \\\n",
       "0  <p>Windows 11 with wsl2 ubuntu-22.04.</p>\\n<p>...          73247188.0   \n",
       "1  <p>I am trying to get the Azure log query data...                 NaN   \n",
       "2  <p>I have these errors when trying to write th...          73251390.0   \n",
       "\n",
       "   answer_count  comment_count community_owned_date  \\\n",
       "0             1              0                  NaT   \n",
       "1             2              0                  NaT   \n",
       "2             1              0                  NaT   \n",
       "\n",
       "                     creation_date  favorite_count  \\\n",
       "0 2022-08-02 16:16:31.810000+00:00             NaN   \n",
       "1 2022-08-08 21:53:16.703000+00:00             NaN   \n",
       "2 2022-08-05 13:43:25.850000+00:00             NaN   \n",
       "\n",
       "                last_activity_date                   last_edit_date  \\\n",
       "0 2022-08-05 09:00:14.693000+00:00 2022-08-02 16:32:13.700000+00:00   \n",
       "1 2022-08-10 04:49:20.527000+00:00 2022-08-09 08:12:13.920000+00:00   \n",
       "2 2022-08-05 16:40:00.610000+00:00 2022-08-05 16:40:00.610000+00:00   \n",
       "\n",
       "  last_editor_display_name  last_editor_user_id owner_display_name  \\\n",
       "0                     None             11226740               None   \n",
       "1                     None              2395282               None   \n",
       "2                     None             17654458               None   \n",
       "\n",
       "   owner_user_id parent_id  post_type_id  score  \\\n",
       "0       11226740      None             1      0   \n",
       "1       19123691      None             1      0   \n",
       "2       17654458      None             1      3   \n",
       "\n",
       "                                                tags  view_count  \n",
       "0             azure-container-registry|docker-daemon         256  \n",
       "1  azure|azure-devops|azure-application-insights|...         256  \n",
       "2                                         c#|unity3d         512  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack_overflow_df = query_job\\\n",
    "    .result()\\\n",
    "    .to_arrow()\\\n",
    "    .to_pandas()\n",
    "stack_overflow_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62227120-4966-4114-bf89-add35dacc093",
   "metadata": {},
   "source": [
    "### Dealing with Large Datasets\n",
    "\n",
    "- Large datasets for LLMs often don't fit into memory.\n",
    "- Select all of the columns and rows of the table `posts_questions`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "daa96507-e39a-4f10-bdac-c254752b0d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_ALL = \"\"\"\n",
    "SELECT\n",
    "    *\n",
    "FROM\n",
    "    `bigquery-public-data.stackoverflow.posts_questions` q\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b3ce316a-1303-46f6-b768-8c661a3d9ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_job = bq_client.query(QUERY_ALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "91e9ec25-3496-4e5c-9c13-ba5dcd19ba15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The DataFrame is too large to load into memory. 403 Response too large to return. Consider specifying a destination table in your job configuration. For more details, see https://cloud.google.com/bigquery/troubleshooting-errors; reason: responseTooLarge, message: Response too large to return. Consider specifying a destination table in your job configuration. For more details, see https://cloud.google.com/bigquery/troubleshooting-errors\n",
      "\n",
      "Location: US\n",
      "Job ID: f16990bc-eaee-4d7f-892e-81d5a55006ba\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    stack_overflow_df = query_job\\\n",
    "    .result()\\\n",
    "    .to_arrow()\\\n",
    "    .to_pandas()\n",
    "except Exception as e:\n",
    "    print('The DataFrame is too large to load into memory.', e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e90eb1-da33-4939-9de6-496a5c4fd09b",
   "metadata": {},
   "source": [
    "**Note:** The data is too large to return, as it is not fitting into memory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc28a24-0437-4190-b9c1-3d0ffd2fb359",
   "metadata": {},
   "source": [
    "#### Joining Tables and Query Optimization\n",
    "\n",
    "- When working with (large) data, query optimizing is needed in order to save time and resources.\n",
    "- Select questions as `input_text` (column 1), answers as `output_text` (column 2).\n",
    "- Take the questions from `posts_questions` and answers from `posts_answers`.\n",
    "- Join the questions and their corresponding accepted answers based on their same `unique ID`.\n",
    "- Making sure the question is about `Python`, and that it `has an answer`. And the date the question was posted is on or after `2020-01-01`\n",
    "- Limit as 10,000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8de4c705-29fe-4977-bf6f-7723d7273fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY = \"\"\"\n",
    "SELECT\n",
    "    CONCAT(q.title, q.body) as input_text,\n",
    "    a.body AS output_text\n",
    "FROM\n",
    "    `bigquery-public-data.stackoverflow.posts_questions` q\n",
    "JOIN\n",
    "    `bigquery-public-data.stackoverflow.posts_answers` a\n",
    "ON\n",
    "    q.accepted_answer_id = a.id\n",
    "WHERE\n",
    "    q.accepted_answer_id IS NOT NULL AND\n",
    "    REGEXP_CONTAINS(q.tags, \"python\") AND\n",
    "    a.creation_date >= \"2020-01-01\"\n",
    "LIMIT\n",
    "    10000\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b510cec9-aaa7-48c0-b6f5-ca9cf6f9089a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_job = bq_client.query(QUERY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "99b2d7eb-74c7-4dea-abff-6e9a5d101b41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_text</th>\n",
       "      <th>output_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomWalker Segmentation algorithm results in...</td>\n",
       "      <td>&lt;p&gt;Random walker only &lt;em&gt;expands&lt;/em&gt; labels ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How to get numpy.exp to work with an array as ...</td>\n",
       "      <td>&lt;p&gt;You have to encapsulate the denominator of ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          input_text  \\\n",
       "0  RandomWalker Segmentation algorithm results in...   \n",
       "1  How to get numpy.exp to work with an array as ...   \n",
       "\n",
       "                                         output_text  \n",
       "0  <p>Random walker only <em>expands</em> labels ...  \n",
       "1  <p>You have to encapsulate the denominator of ...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### this may take some seconds to run\n",
    "stack_overflow_df = query_job.result()\\\n",
    "                        .to_arrow()\\\n",
    "                        .to_pandas()\n",
    "\n",
    "stack_overflow_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97062dae-4281-450c-9459-ff7c2d5cedde",
   "metadata": {},
   "source": [
    "### Adding Instructions\n",
    "\n",
    "- Instructions for LLMs have been shown to improve model performance and generalization to unseen tasks [(Google, 2022)](https://arxiv.org/pdf/2210.11416.pdf).\n",
    "- Wihtout the instruction, it is only question and answer. Model might not understand what to do.\n",
    "- With the instructions, the model gets a guideline as to what task to perform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "05a22916-1af7-44e2-9190-75be8dde04a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "INSTRUCTION_TEMPLATE = f\"\"\"\\\n",
    "Please answer the following Stack overflow question on Python. \\\n",
    "Answer it like you are a developer answering Stack overflow questions.\n",
    "\n",
    "Stack overflow question:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facbb014-4ae2-4f33-a344-b623958657c4",
   "metadata": {},
   "source": [
    "- A new column will combine `INSTRUCTION_TEMPLATE` and the question `input_text`.\r\n",
    "- This avoids overwritting of any existing column which might be needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9bdcd7dc-4cf2-433b-a237-04c8c0f326b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_overflow_df['input_text_instruct'] = INSTRUCTION_TEMPLATE + ' ' + stack_overflow_df['input_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ced664d-247d-4a9c-9700-dec762d50dac",
   "metadata": {},
   "source": [
    "### Dataset for Tuning\r\n",
    "\r\n",
    "- Divide the data into a training and evaluation. By default, 80/20 split is used.\r\n",
    "- This (80/20 split) allows for more data to be used for tuni\n",
    "- g. The evaluation split is used as unseen data during tuning to evaluate performance.\r\n",
    "- The `random_state` parameter is used to ensure random sampling for a fair comparison. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "967db832-8fbe-443a-a3ff-0da1e2476f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, evaluation = train_test_split(\n",
    "    stack_overflow_df,\n",
    "    ### test_size=0.2 means 20% for evaluation\n",
    "    ### which then makes train set to be of 80%\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5685fd-4315-491f-bd81-1ce558759a49",
   "metadata": {},
   "source": [
    "#### Different Datasets and Flow\n",
    "\n",
    "- Versioning data is important.\n",
    "- It allows for reproducibility, traceability, and maintainability of machine learning models.\n",
    "- Get the timestamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c7c3729e-b254-4189-915d-81bab535442b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "date = datetime.datetime.now().strftime(\"%H_%d_%m_%Y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2444592d-9da1-4b9e-a311-77191d35ee17",
   "metadata": {},
   "source": [
    "- Generate a `jsonl` file.\n",
    "- Name it as `tune_data_stack_overflow_python_qa-{date}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7e8b503b-d511-4c2c-b2c0-f2bc4aec8da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['input_text_instruct','output_text']\n",
    "tune_jsonl = train[cols].to_json(orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cb71f0f0-81ea-4c3e-a0e6-1322b1256c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_filename = f\"tune_data_stack_overflow_python_qa-{str(date)}.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9b28b4f1-bd7d-4f7f-b916-7cbf7cf2602f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('GenAI_and_LLMOps/' + training_data_filename, \"w\") as f:\n",
    "    f.write(tune_jsonl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c65be4-a5fc-43a9-93d6-f6ba910adad4",
   "metadata": {},
   "source": [
    "### Evaluation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4ce0a45b-5811-494e-a961-710872273f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['input_text_instruct','output_text']\n",
    "tune_jsonl = evaluation[cols].to_json(orient=\"records\", lines=True)\n",
    "\n",
    "### change the file name\n",
    "### use \"tune_eval_data_stack_overflow_python_qa-{date}.jsonl\"\n",
    "evaluation_data_filename = f\"tune_eval_data_stack_overflow_python_qa-{str(date)}.jsonl\"\n",
    "\n",
    "### write the file\n",
    "with open('GenAI_and_LLMOps/' + evaluation_data_filename, \"w\") as f:\n",
    "    f.write(tune_jsonl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a1bbb9-6a9f-4167-9994-e971f7df6f6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3693c14c-2208-4edd-befd-0a619ff2aaa2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
